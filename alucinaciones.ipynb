{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "azure_search_endpoint = os.getenv('AZURE_SEARCH_ENDPOINT')\n",
    "azure_search_key = os.getenv('AZURE_SEARCH_KEY')\n",
    "azure_openai_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "openai_api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "openai_deployment = os.getenv('AZURE_OPENAI_DEPLOYMENT')\n",
    "openai_api_version = os.getenv('OPENAI_API_VERSION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# Carga modelo NLP para analizar coherencia\n",
    "# nlp = spacy.load(\"xx_ent_wiki_sm\")\n",
    "\n",
    "# Cargar texto y dividir en fragmentos\n",
    "with open('anatomy.txt', 'r', encoding='utf-8') as f:\n",
    "    file = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_text(file)\n",
    "\n",
    "# Crear documentos\n",
    "documentos = [Document(page_content=chunk) for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import AzureSearch\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# Crear índice de búsqueda vectorial en Azure\n",
    "chunk_store = AzureSearch.from_documents(\n",
    "    azure_search_endpoint=azure_search_endpoint,\n",
    "    azure_search_key=azure_search_key,\n",
    "    documents=documentos,\n",
    "    embedding=OllamaEmbeddings(model='nomic-embed-text:latest')\n",
    ")\n",
    "\n",
    "chunks_vector = chunk_store.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_vector = chunk_store.as_retriever(k=1)\n",
    "question = \"qué contiene el libro proyecto gutenberg?\"\n",
    "docs = chunks_vector.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section 2. Information about the Mission of Project Gutenberg™\n",
      "\n",
      "Project Gutenberg™ is synonymous with the free distribution of\n",
      "electronic works in formats readable by the widest variety of\n",
      "computers including obsolete, old, middle-aged and new computers. It\n",
      "exists because of the efforts of hundreds of volunteers and donations\n",
      "from people in all walks of life.\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "          print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\argui\\OneDrive\\Escritorio\\Hackathon_IA\\env\\Lib\\site-packages\\langsmith\\client.py:261: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El libro Proyecto Gutenberg contiene obras electrónicas de distribución gratuita en formatos compatibles con una amplia variedad de computadoras.\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=openai_deployment,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    api_key=openai_api_key,\n",
    "    api_version=openai_api_version,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "generation = rag_chain.invoke({\"context\": format_docs(docs), \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hallucination Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\argui\\OneDrive\\Escritorio\\Hackathon_IA\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3577: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradeHallucinations(binary_score='yes')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "# Data model\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=openai_deployment,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    api_key=openai_api_key,\n",
    "    api_version=openai_api_version,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "\n",
    "structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n \n",
    "     Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\"\"\"\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "hallucination_grader = hallucination_prompt | structured_llm_grader\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieval Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "# LLM with function call\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=openai_deployment,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    api_key=openai_api_key,\n",
    "    api_version=openai_api_version,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "question = \"agent memory\"\n",
    "docs = chunks_vector.get_relevant_documents(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=openai_deployment,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    api_key=openai_api_key,\n",
    "    api_version=openai_api_version,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "question = \"agent memory\"\n",
    "docs = chunks_vector.invoke(question)\n",
    "\n",
    "# Run\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "# Modelo de LLM para evaluación de relevancia\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"Puntuación binaria para la alucinación presente en la respuesta de la generación.\"\"\"\n",
    "    binary_score: str = Field(\n",
    "        description=\"La respuesta se basa en los hechos, «sí» o «no\"\n",
    "    )\n",
    " \n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=openai_deployment,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    api_key=openai_api_key,\n",
    "    api_version=openai_api_version,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
    "\n",
    "system = \"\"\"Usted es un calificador que evalúa si una generación de LLM está fundamentada / apoyada por un conjunto de hechos recuperados. \\n \n",
    "     Da una puntuación binaria 'sí' o 'no'. Sí' significa que la respuesta está basada / apoyada por el conjunto de hechos.\"\"\"\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Set of facts: \\n\\n {document} \\n\\n LLM generation: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hallucination_grader = hallucination_prompt | structured_llm_grader\n",
    "generation = hallucination_grader.invoke({\"context\": docs, \"question\": question})\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema import Document\n",
    "from langchain_community.vectorstores import AzureSearch\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "# Carga modelo NLP para analizar coherencia\n",
    "nlp = spacy.load(\"xx_ent_wiki_sm\")\n",
    "\n",
    "# Cargar texto y dividir en fragmentos\n",
    "with open('anatomy.txt', 'r', encoding='utf-8') as f:\n",
    "    file = f.read()\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_text(file)\n",
    "\n",
    "# Crear documentos\n",
    "documentos = [Document(page_content=chunk) for chunk in chunks]\n",
    "\n",
    "# Crear índice de búsqueda vectorial en Azure\n",
    "chunk_store = AzureSearch.from_documents(\n",
    "    azure_search_endpoint=azure_search_endpoint,\n",
    "    azure_search_key=azure_search_key,\n",
    "    documents=documentos,\n",
    "    embedding=OllamaEmbeddings(model='nomic-embed-text:latest')\n",
    ")\n",
    "\n",
    "chunks_vector = chunk_store.as_retriever()\n",
    "\n",
    "# Modelo de LLM para evaluación de relevancia\n",
    "class GradeDocuments(BaseModel):\n",
    "    binary_score: str = Field(\n",
    "        description=\"Los documentos son relevantes para la pregunta 'sí' o 'no'.\"\n",
    "    )\n",
    " \n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=openai_deployment,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    api_key=openai_api_key,\n",
    "    api_version=openai_api_version,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# Prompt para evaluar relevancia\n",
    "system = \"\"\"Eres un calificador que evalúa la relevancia de un documento recuperado con respecto a una pregunta del usuario.\n",
    "Si el documento contiene palabras clave o significados semánticos relacionados con la pregunta del usuario, califíquelo como pertinente.\n",
    "Dar una puntuación binaria «sí» o «no» para indicar si el documento es pertinente para la pregunta.\"\"\"\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "\n",
    "# Función para analizar coherencia interna\n",
    "def analizar_coherencia(texto):\n",
    "    \"\"\"Analiza la coherencia interna de un texto.\"\"\"\n",
    "    doc = nlp(texto)\n",
    "    inconsistencias = []\n",
    "    for sent in doc.sents:\n",
    "        tokens = [token.text for token in sent if token.dep_ == \"neg\"]\n",
    "        if tokens:\n",
    "            inconsistencias.append(sent.text)\n",
    "    return inconsistencias\n",
    "\n",
    "# Orquestador para detectar alucinaciones y problemas de coherencia\n",
    "def evaluar_texto(question):\n",
    "    \"\"\"Evalúa un texto en busca de alucinaciones y problemas de coherencia.\"\"\"\n",
    "    # Recuperar documentos relevantes\n",
    "    docs = chunks_vector.get_relevant_documents(question)\n",
    "    if not docs:\n",
    "        return {\n",
    "            \"alucinaciones_probabilidad\": 1.0,\n",
    "            \"comentarios\": \"No se encontraron documentos relevantes para la pregunta.\",\n",
    "            \"acciones_recomendadas\": [\"Agregar documentos relevantes al índice de Azure.\"]\n",
    "        }\n",
    "\n",
    "    # Evaluar relevancia con el modelo\n",
    "    relevancia = []\n",
    "    for doc in docs:\n",
    "        doc_txt = doc.page_content\n",
    "        result = retrieval_grader.invoke({\"question\": question, \"document\": doc_txt})\n",
    "        relevancia.append(result[\"binary_score\"] == \"yes\")\n",
    "\n",
    "    # Detectar alucinaciones\n",
    "    probabilidad_alucinacion = 1.0 - sum(relevancia) / len(relevancia) if relevancia else 1.0\n",
    "\n",
    "    # Analizar coherencia de los documentos recuperados\n",
    "    inconsistencias = []\n",
    "    for doc in docs:\n",
    "        inconsistencias.extend(analizar_coherencia(doc.page_content))\n",
    "\n",
    "    # Generar reporte\n",
    "    comentarios = []\n",
    "    if probabilidad_alucinacion > 0.5:\n",
    "        comentarios.append(\"La información parece ficticia o no respaldada por los documentos.\")\n",
    "    if inconsistencias:\n",
    "        comentarios.append(f\"Inconsistencias detectadas en los documentos: {', '.join(inconsistencias)}\")\n",
    "\n",
    "    return {\n",
    "        \"alucinaciones_probabilidad\": probabilidad_alucinacion,\n",
    "        \"comentarios\": \" \".join(comentarios),\n",
    "        \"acciones_recomendadas\": [\n",
    "            \"Verificar el contenido manualmente.\",\n",
    "            \"Agregar más datos relevantes al índice de Azure.\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Ejemplo de uso\n",
    "question = \"agent memory\"\n",
    "reporte = evaluar_texto(question)\n",
    "print(reporte)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
